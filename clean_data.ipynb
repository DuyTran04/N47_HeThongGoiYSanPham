{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8001fa8-d880-4c95-9ba8-7d085f8dda50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang thử đọc với encoding: utf-8\n",
      "Đọc thành công với encoding: utf-8\n",
      "Loaded data: 599137 rows, 25 columns\n",
      "\n",
      "Kiểm tra dữ liệu ban đầu:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 599137 entries, 0 to 599136\n",
      "Data columns (total 25 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   product_id           599137 non-null  object \n",
      " 1   product_name         599136 non-null  object \n",
      " 2   category             599137 non-null  object \n",
      " 3   discounted_price     599137 non-null  object \n",
      " 4   actual_price         599137 non-null  object \n",
      " 5   discount_percentage  599137 non-null  object \n",
      " 6   rating               599137 non-null  float64\n",
      " 7   rating_count         599137 non-null  int64  \n",
      " 8   about_product        599117 non-null  object \n",
      " 9   user_name            599137 non-null  object \n",
      " 10  review_id            599137 non-null  object \n",
      " 11  review_title         599087 non-null  object \n",
      " 12  review_content       599133 non-null  object \n",
      " 13  img_link             599137 non-null  object \n",
      " 14  product_link         599137 non-null  object \n",
      " 15  user_id              599137 non-null  object \n",
      " 16  Timestamp            599137 non-null  object \n",
      " 17  Search_Frequency     599137 non-null  int64  \n",
      " 18  user_id_count        599137 non-null  int64  \n",
      " 19  timestamp_count      599137 non-null  int64  \n",
      " 20  Keywords             599137 non-null  object \n",
      " 21  Category_Keywords    599137 non-null  object \n",
      " 22  Product_Keywords     599137 non-null  object \n",
      " 23  Generated_Keywords   599137 non-null  object \n",
      " 24  Keyword_Count        599137 non-null  int64  \n",
      "dtypes: float64(1), int64(5), object(19)\n",
      "memory usage: 114.3+ MB\n",
      "None\n",
      "\n",
      "Mẫu dữ liệu:\n",
      "   product_id                                       product_name    category  \\\n",
      "0  B00YQ6X8EO  Herbivore - Natural Sea Mist Texturizing Salt ...  All Beauty   \n",
      "1  B081TJ8YS3  All Natural Vegan Dry Shampoo Powder - Eco Fri...  All Beauty   \n",
      "2  B097R46CSY  New Road Beauty - Creamsicle - Variety 3 Pack ...  All Beauty   \n",
      "3  B09JS339BZ  muaowig Ombre Body Wave Bundles 1B Grey Human ...  All Beauty   \n",
      "4  B08BZ63GMJ  Yinhua Electric Nail Drill Kit Portable Profes...  All Beauty   \n",
      "\n",
      "  discounted_price actual_price discount_percentage  rating  rating_count  \\\n",
      "0           ₹8,532      ₹18,960                 55%     4.3           384   \n",
      "1           ₹3,046       ₹3,385                 10%     4.0            56   \n",
      "2           ₹1,203       ₹1,648                 27%     4.4           699   \n",
      "3           ₹3,198      ₹19,988                 84%     1.0             1   \n",
      "4           ₹6,187       ₹8,249                 25%     3.5            20   \n",
      "\n",
      "                                       about_product        user_name  ...  \\\n",
      "0  If given the choice; weÕd leave most telltale ...      Liam Garcia  ...   \n",
      "1  This product does what I need it to do; I just...  Taylor Martinez  ...   \n",
      "2  Same Great Product; NEW PACKAGING. MOISTURIZED...     Morgan White  ...   \n",
      "3  ?Hair Bundle Material?:Brazilian Virgin Human ...      Avery Brown  ...   \n",
      "4                                            Love it    Morgan Wilson  ...   \n",
      "\n",
      "                        user_id Timestamp Search_Frequency user_id_count  \\\n",
      "0  AFBSJWOQVCMDM5OFGBA737M26LIQ   06:18.2                8             5   \n",
      "1  AFBSJWOQVCMDM5OFGBA737M26LIQ   09:36.3                1             5   \n",
      "2  AGWL3EXVR7WDNRFTULHP3XUZZY7Q   16:28.7               10             5   \n",
      "3  AH2KAMNL2MDM7EQUJ6ZRZODGEUGQ   02:44.6                5             5   \n",
      "4  AH2KAMNL2MDM7EQUJ6ZRZODGEUGQ   20:39.9                8             5   \n",
      "\n",
      "  timestamp_count                                           Keywords  \\\n",
      "0               5    ['sprawl', 'signs', 'swim', 'thing', 'imparts']   \n",
      "1               9  ['soft', 'odorless', 'product', 'hav', 'coconut']   \n",
      "2               6  ['soft', 'benefits', 'lavender', 'instantly', ...   \n",
      "3               6      ['soft', 'making', 'little', 'every', 'comb']   \n",
      "4               8                                           ['love']   \n",
      "\n",
      "  Category_Keywords                                   Product_Keywords  \\\n",
      "0        ['beauty']  ['texturizing', 'salt', 'coconut', 'mist', 'sea']   \n",
      "1        ['beauty']      ['friendly', 'root', 'brown', 'dry', 'brush']   \n",
      "2        ['beauty']  ['beauty', 'new', 'nourishing', 'moisturize', ...   \n",
      "3        ['beauty']          ['muao', 'wave', 'inch', 'grey', 'weave']   \n",
      "4        ['beauty']   ['bands', 'portable', 'nail', 'sanding', 'bits']   \n",
      "\n",
      "                                  Generated_Keywords  Keyword_Count  \n",
      "0         ['texturizing', 'salt', 'coconut', 'mist']              4  \n",
      "1               ['friendly', 'root', 'brown', 'dry']              4  \n",
      "2  ['beauty', 'beauty', 'new', 'nourishing', 'moi...              5  \n",
      "3          ['muao', 'wave', 'inch', 'grey', 'weave']              5  \n",
      "4                    ['beauty', 'bands', 'portable']              3  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Initial Load - Columns with NaN values:\n",
      "  product_name: 1 NaNs\n",
      "  about_product: 20 NaNs\n",
      "  review_title: 50 NaNs\n",
      "  review_content: 4 NaNs\n",
      "\n",
      "After Cleaning Prices, Discounts & Ratings - Columns with NaN values:\n",
      "  product_name: 1 NaNs\n",
      "Số lượng người dùng: 5000\n",
      "Số lượng sản phẩm: 599137\n",
      "Số lượng đánh giá: 599137\n",
      "Phân phối rating trước khi xử lý:\n",
      "rating\n",
      "1.0     5307\n",
      "1.1        5\n",
      "1.2       23\n",
      "1.3       83\n",
      "1.4      145\n",
      "1.5      453\n",
      "1.6      140\n",
      "1.7      175\n",
      "1.8      224\n",
      "1.9      243\n",
      "2.0     2657\n",
      "2.1      496\n",
      "2.2      628\n",
      "2.3      786\n",
      "2.4     1097\n",
      "2.5     1937\n",
      "2.6     1932\n",
      "2.7     2812\n",
      "2.8     3298\n",
      "2.9     4358\n",
      "3.0    12138\n",
      "3.1     8482\n",
      "3.2    10394\n",
      "3.3    13433\n",
      "3.4    15119\n",
      "3.5    18654\n",
      "3.6    20378\n",
      "3.7    23611\n",
      "3.8    26361\n",
      "3.9    29121\n",
      "4.0    38887\n",
      "4.1    37206\n",
      "4.2    41144\n",
      "4.3    44363\n",
      "4.4    48097\n",
      "4.5    51700\n",
      "4.6    43767\n",
      "4.7    31129\n",
      "4.8    15375\n",
      "4.9     4567\n",
      "5.0    38412\n",
      "Name: count, dtype: int64\n",
      "Trọng số của các rating: {4.3: 0.32939831753884113, 4.0: 0.3757836182008283, 4.4: 0.30382555171789527, 1.0: 2.7535514529820255, 3.5: 0.7833760888268259, 3.8: 0.5543453420194837, 3.1: 1.7228363075896733, 4.5: 0.2826517903476907, 3.3: 1.0878506335871072, 4.2: 0.3551695887851354, 3.7: 0.6189105739263737, 4.1: 0.39276185456581225, 3.4: 0.9665386309263582, 3.9: 0.5018061728984448, 3.2: 1.4059166404633068, 5.0: 0.3804305311094348, 3.0: 1.203913129096689, 4.6: 0.3338839207845091, 2.7: 5.196691878014086, 3.6: 0.7171016567364613, 4.8: 0.9504453698195519, 4.7: 0.4694367811679016, 2.9: 3.35316603051299, 2.5: 7.54419079038493, 2.6: 7.563715093672676, 2.8: 4.430896774098123, 4.9: 3.1997148151906307, 1.8: 65.23704268292683, 2.1: 29.461890243902438, 2.0: 5.499848536309977, 2.3: 18.59172717681375, 2.4: 13.32096404829135, 2.2: 23.269263632126766, 1.4: 100.77998317914214, 1.5: 32.25849351208744, 1.6: 104.37926829268292, 1.9: 60.13620395463214, 1.7: 83.50341463414634, 1.3: 176.0614163972965, 1.2: 635.3520678685047, 1.1: 2922.619512195122}\n",
      "\n",
      "After Preprocessing - Columns with NaN values:\n",
      "  product_name: 1 NaNs\n",
      "\n",
      "After Fixing Missing rating_count - Columns with NaN values:\n",
      "  product_name: 1 NaNs\n",
      "\n",
      "After Calculating Purchase Count - Columns with NaN values:\n",
      "  product_name: 1 NaNs\n",
      "\n",
      "After Handling Outliers - Columns with NaN values:\n",
      "  product_name: 1 NaNs\n",
      "\n",
      "Cleaned data saved to amazon_cleaned.csv\n",
      "Final shape: 599137 rows, 18 columns\n",
      "\n",
      "Final columns:\n",
      "  - product_id\n",
      "  - product_name\n",
      "  - category\n",
      "  - review_id\n",
      "  - rating\n",
      "  - rating_count\n",
      "  - review_count\n",
      "  - discounted_price\n",
      "  - actual_price\n",
      "  - discount_percentage\n",
      "  - purchase_count_estimated\n",
      "  - user_id\n",
      "  - user_idx\n",
      "  - product_idx\n",
      "  - scaled_rating\n",
      "  - Search_Frequency\n",
      "  - Timestamp\n",
      "  - Generated_Keywords\n",
      "Class weights saved to class_weights.json\n",
      "\n",
      "Biểu đồ phân tích đã được lưu:\n",
      "  - price_distribution.png\n",
      "  - rating_count_distribution.png\n",
      "  - rating_distribution.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import rankdata, skew\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, QuantileTransformer\n",
    "from sklearn.utils import resample\n",
    "import traceback\n",
    "import re\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Hàm để thử nhiều kiểu encoding cho đến khi đọc được file\n",
    "def read_csv_with_multiple_encodings(file_path, encodings=['utf-8', 'latin1', 'ISO-8859-1', 'cp1252']):\n",
    "    \"\"\"\n",
    "    Thử đọc file CSV với nhiều kiểu encoding khác nhau cho đến khi thành công.\n",
    "    \"\"\"\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            print(f\"Đang thử đọc với encoding: {encoding}\")\n",
    "            df = pd.read_csv(file_path, encoding=encoding)\n",
    "            print(f\"Đọc thành công với encoding: {encoding}\")\n",
    "            return df\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Không thể đọc với encoding: {encoding}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khác: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    try:\n",
    "        print(\"Đang thử đọc với engine='python' và encoding='latin1'\")\n",
    "        return pd.read_csv(file_path, encoding='latin1', engine='python')\n",
    "    except Exception as e:\n",
    "        print(f\"Tất cả các phương pháp đều thất bại: {str(e)}\")\n",
    "        try:\n",
    "            print(\"Đang thử phương pháp cuối cùng: đọc file dạng nhị phân\")\n",
    "            import io\n",
    "            with open(file_path, 'rb') as f:\n",
    "                content = f.read()\n",
    "                content = content.decode('latin1').encode('utf-8', 'replace').decode('utf-8')\n",
    "                return pd.read_csv(io.StringIO(content))\n",
    "        except Exception as final_e:\n",
    "            print(f\"Không thể đọc file với bất kỳ phương pháp nào: {str(final_e)}\")\n",
    "            raise\n",
    "\n",
    "# ====== CLEANING FUNCTIONS ======\n",
    "def clean_price(price_str):\n",
    "    \"\"\"Làm sạch giá từ chuỗi\"\"\"\n",
    "    if pd.isna(price_str):\n",
    "        return 0.0\n",
    "    \n",
    "    if isinstance(price_str, str):\n",
    "        price_clean = re.sub(r'[^\\d.]', '', price_str)\n",
    "        if price_clean:\n",
    "            try:\n",
    "                return float(price_clean)\n",
    "            except:\n",
    "                return 0.0\n",
    "        return 0.0\n",
    "    \n",
    "    try:\n",
    "        return float(price_str) if pd.notna(price_str) else 0.0\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def clean_percentage(percentage_str):\n",
    "    \"\"\"Làm sạch phần trăm từ chuỗi\"\"\"\n",
    "    if pd.isna(percentage_str):\n",
    "        return 0.0\n",
    "    \n",
    "    if isinstance(percentage_str, str):\n",
    "        percentage_clean = re.sub(r'[^\\d.]', '', percentage_str)\n",
    "        if percentage_clean:\n",
    "            try:\n",
    "                return float(percentage_clean) / 100\n",
    "            except:\n",
    "                return 0.0\n",
    "        return 0.0\n",
    "    \n",
    "    try:\n",
    "        return float(percentage_str) if pd.notna(percentage_str) else 0.0\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def clean_rating_count(rating_count_str):\n",
    "    \"\"\"Làm sạch số lượng đánh giá từ chuỗi\"\"\"\n",
    "    if pd.isna(rating_count_str):\n",
    "        return 0\n",
    "    \n",
    "    if isinstance(rating_count_str, str):\n",
    "        count_clean = re.sub(r'[^\\d]', '', rating_count_str)\n",
    "        if count_clean:\n",
    "            try:\n",
    "                return int(count_clean)\n",
    "            except:\n",
    "                return 0\n",
    "        return 0\n",
    "    \n",
    "    try:\n",
    "        return int(rating_count_str) if pd.notna(rating_count_str) else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# ====== NORMALIZATION ======\n",
    "def normalize_numeric(df):\n",
    "    \"\"\"Chuẩn hóa các cột số\"\"\"\n",
    "    numeric_columns = ['rating', 'rating_count', 'review_count', \n",
    "                       'discounted_price', 'actual_price', 'discount_percentage']\n",
    "    for col in numeric_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "            df[col] = df[col].clip(0)  # không cho giá trị âm\n",
    "    return df\n",
    "\n",
    "# ====== OUTLIER HANDLING ======\n",
    "def handle_outliers(df, columns):\n",
    "    \"\"\"Xử lý ngoại lai bằng phương pháp IQR\"\"\"\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            Q1 = df[column].quantile(0.25)\n",
    "            Q3 = df[column].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            df[column] = df[column].clip(lower=lower_bound, upper=upper_bound)\n",
    "    return df\n",
    "\n",
    "# ====== ENCODING ======\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Tiền xử lý dữ liệu chính và tính trọng số cho rating\"\"\"\n",
    "    # Loại bỏ các dòng thiếu user_id, product_id, hoặc rating\n",
    "    df = df.dropna(subset=['user_id', 'product_id', 'rating'])\n",
    "    \n",
    "    # Xử lý user_id nếu chứa nhiều ID (phân tách bằng dấu phẩy)\n",
    "    df['user_id'] = df['user_id'].apply(\n",
    "        lambda x: x.split(',')[0].strip() if isinstance(x, str) and ',' in x else x\n",
    "    )\n",
    "    \n",
    "    # Đảm bảo rating là số và trong phạm vi 1-5\n",
    "    df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
    "    df = df.dropna(subset=['rating'])  # Loại bỏ những dòng với rating không hợp lệ\n",
    "    df['rating'] = df['rating'].clip(1, 5)\n",
    "    \n",
    "    # Chuẩn hóa rating để cải thiện sự ổn định trong huấn luyện\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df['scaled_rating'] = scaler.fit_transform(df[['rating']])\n",
    "    \n",
    "    # Mã hóa user_id và product_id thành chỉ số số nguyên\n",
    "    user_encoder = LabelEncoder()\n",
    "    product_encoder = LabelEncoder()\n",
    "    \n",
    "    df['user_idx'] = user_encoder.fit_transform(df['user_id'])\n",
    "    df['product_idx'] = product_encoder.fit_transform(df['product_id'])\n",
    "    \n",
    "    # Tạo từ điển ánh xạ ngược để hiển thị kết quả\n",
    "    idx_to_product = {idx: product for idx, product in zip(df['product_idx'], df['product_id'])}\n",
    "    product_to_name = {pid: name for pid, name in zip(df['product_id'], df['product_name'])}\n",
    "    \n",
    "    # Tính trọng số cho các giá trị rating\n",
    "    rating_counts = Counter(df['rating'])\n",
    "    total_samples = len(df)\n",
    "    num_classes = len(rating_counts)\n",
    "    class_weights = {rating: total_samples / (num_classes * count) \n",
    "                    for rating, count in rating_counts.items()}\n",
    "    \n",
    "    # Thống kê\n",
    "    num_users = df['user_idx'].nunique()\n",
    "    num_products = df['product_idx'].nunique()\n",
    "    print(f\"Số lượng người dùng: {num_users}\")\n",
    "    print(f\"Số lượng sản phẩm: {num_products}\")\n",
    "    print(f\"Số lượng đánh giá: {len(df)}\")\n",
    "    print(\"Phân phối rating trước khi xử lý:\")\n",
    "    print(df['rating'].value_counts().sort_index())\n",
    "    print(\"Trọng số của các rating:\", class_weights)\n",
    "    \n",
    "    return df, user_encoder, product_encoder, idx_to_product, product_to_name, scaler, class_weights\n",
    "\n",
    "# ====== FEATURE ENGINEERING ======\n",
    "def calculate_purchase_count_estimated(df):\n",
    "    \"\"\"Tính toán số lượng mua ước tính dựa trên các đặc trưng\"\"\"\n",
    "    a, b, c, d = 5, 0.2, 0.01, 1\n",
    "    df['purchase_count_estimated'] = (\n",
    "        a * df['rating'] +\n",
    "        b * df['discount_percentage'] +\n",
    "        c * df['actual_price'] +\n",
    "        d * df['review_count']\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# ====== OVERSAMPLING FOR MISSING RATING_COUNT ======\n",
    "def fix_rating_count_with_oversampling(df):\n",
    "    \"\"\"Sửa các giá trị thiếu trong rating_count bằng oversampling\"\"\"\n",
    "    df['rating_count'] = df['rating_count'].fillna(0)\n",
    "    df['rating_count'] = pd.to_numeric(df['rating_count'], errors='coerce')\n",
    "\n",
    "    missing_mask = df['rating_count'] == 0\n",
    "    if not missing_mask.any():\n",
    "        return df\n",
    "\n",
    "    product_avg = df[~missing_mask].groupby('product_id')['rating_count'].mean()\n",
    "    global_avg = df['rating_count'].mean()\n",
    "    global_avg = int(global_avg)\n",
    "\n",
    "    for idx in df[missing_mask].index:\n",
    "        product_id = df.loc[idx, 'product_id']\n",
    "        if product_id in product_avg:\n",
    "            df.loc[idx, 'rating_count'] = product_avg[product_id]\n",
    "        else:\n",
    "            df.loc[idx, 'rating_count'] = global_avg\n",
    "\n",
    "    noise = np.random.normal(0, 0.1, len(df[missing_mask]))\n",
    "    df.loc[missing_mask, 'rating_count'] = (df.loc[missing_mask, 'rating_count'] * (1 + noise)).astype(int)\n",
    "    df['rating_count'] = df['rating_count'].clip(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# ====== CHECK NaN ======\n",
    "def print_columns_with_nan(df, step_name):\n",
    "    \"\"\"Kiểm tra và in ra các cột có giá trị NaN\"\"\"\n",
    "    nan_cols = df.columns[df.isna().any()].tolist()\n",
    "    if nan_cols:\n",
    "        print(f\"\\n{step_name} - Columns with NaN values:\")\n",
    "        for col in nan_cols:\n",
    "            print(f\"  {col}: {df[col].isna().sum()} NaNs\")\n",
    "    else:\n",
    "        print(f\"\\n{step_name} - No NaN values found.\")\n",
    "\n",
    "# ====== DATA ANALYSIS PLOTS ======\n",
    "def plot_analysis(df):\n",
    "    \"\"\"Tạo các biểu đồ phân tích dữ liệu\"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        print(\"Không có dữ liệu để phân tích\")\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        # Phân bố giá\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.histplot(df['discounted_price'], bins=50, kde=True, color='blue', label='Discounted Price')\n",
    "        sns.histplot(df['actual_price'], bins=50, kde=True, color='red', label='Actual Price', alpha=0.5)\n",
    "        plt.xlabel(\"Giá sản phẩm\")\n",
    "        plt.ylabel(\"Số lượng sản phẩm\")\n",
    "        plt.title(\"Phân bố giá giảm và giá thực tế\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"price_distribution.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Phân bố số lượt đánh giá\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(df['rating_count'], bins=50, kde=True, color='purple')\n",
    "        plt.xlabel(\"Số lượt đánh giá\")\n",
    "        plt.ylabel(\"Số lượng sản phẩm\")\n",
    "        plt.title(\"Phân bố số lượt đánh giá\")\n",
    "        plt.xscale('log')  # Dùng log scale nếu dữ liệu phân bố không đều\n",
    "        plt.savefig(\"rating_count_distribution.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Phân bố điểm đánh giá\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(df['rating'], bins=20, kde=True, color='green')\n",
    "        plt.xlabel(\"Điểm đánh giá\")\n",
    "        plt.ylabel(\"Số lượng sản phẩm\")\n",
    "        plt.title(\"Phân bố điểm đánh giá\")\n",
    "        plt.savefig(\"rating_distribution.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"\\nBiểu đồ phân tích đã được lưu:\")\n",
    "        print(\"  - price_distribution.png\")\n",
    "        print(\"  - rating_count_distribution.png\")\n",
    "        print(\"  - rating_distribution.png\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating plots: {str(e)}\")\n",
    "        print(f\"Traceback: {traceback.format_exc()}\")\n",
    "\n",
    "# ====== MAIN PIPELINE ======\n",
    "def main():\n",
    "    try:\n",
    "        # Đọc file CSV với các kiểu encoding khác nhau\n",
    "        df = read_csv_with_multiple_encodings(\"amazon.csv\")\n",
    "        \n",
    "        print(f\"Loaded data: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "        \n",
    "        # Kiểm tra thông tin cơ bản\n",
    "        print(\"\\nKiểm tra dữ liệu ban đầu:\")\n",
    "        print(df.info())\n",
    "        print(\"\\nMẫu dữ liệu:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        # Kiểm tra các cột có NaN\n",
    "        print_columns_with_nan(df, \"Initial Load\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {str(e)}\")\n",
    "        print(f\"Traceback: {traceback.format_exc()}\")\n",
    "        return None, None\n",
    "\n",
    "    # Drop unused columns\n",
    "    columns_to_drop = ['about_product', 'review_content', 'user_name', 'review_title', 'product_link', 'img_link']\n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns], errors='ignore')\n",
    "\n",
    "    # Data Cleaning\n",
    "    df['discounted_price'] = df['discounted_price'].apply(clean_price)\n",
    "    df['actual_price'] = df['actual_price'].apply(clean_price)\n",
    "    df['discount_percentage'] = df['discount_percentage'].apply(clean_percentage)\n",
    "    df['rating_count'] = df['rating_count'].apply(clean_rating_count)\n",
    "    df['rating'] = pd.to_numeric(df['rating'], errors='coerce').fillna(0)\n",
    "\n",
    "    print_columns_with_nan(df, \"After Cleaning Prices, Discounts & Ratings\")\n",
    "\n",
    "    # Preprocess data (encoding, rating scaling, and class weights)\n",
    "    df, user_encoder, product_encoder, idx_to_product, product_to_name, rating_scaler, class_weights = preprocess_data(df)\n",
    "    print_columns_with_nan(df, \"After Preprocessing\")\n",
    "\n",
    "    # Create review_count\n",
    "    if 'review_id' in df.columns:\n",
    "        df['review_count'] = df.groupby('product_id')['review_id'].transform('count')\n",
    "    else:\n",
    "        df['review_count'] = 0\n",
    "    df['review_count'] = pd.to_numeric(df['review_count'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Fix missing rating_count\n",
    "    df = fix_rating_count_with_oversampling(df)\n",
    "    print_columns_with_nan(df, \"After Fixing Missing rating_count\")\n",
    "\n",
    "    # Normalize numeric columns\n",
    "    df = normalize_numeric(df)\n",
    "\n",
    "    # Round discounted_price\n",
    "    df['discounted_price'] = df['discounted_price'].round(1)\n",
    "\n",
    "    # Estimate purchase count\n",
    "    df = calculate_purchase_count_estimated(df)\n",
    "    print_columns_with_nan(df, \"After Calculating Purchase Count\")\n",
    "\n",
    "    # Handle outliers\n",
    "    outlier_columns = [\n",
    "        'rating', 'rating_count', 'discounted_price',\n",
    "        'actual_price', 'discount_percentage', 'purchase_count_estimated'\n",
    "    ]\n",
    "    df = handle_outliers(df, outlier_columns)\n",
    "    print_columns_with_nan(df, \"After Handling Outliers\")\n",
    "\n",
    "    # Select final columns (bao gồm các cột mới từ preprocess_data)\n",
    "    final_columns = [\n",
    "        'product_id', 'product_name', 'category', 'review_id',\n",
    "        'rating', 'rating_count', 'review_count',\n",
    "        'discounted_price', 'actual_price', 'discount_percentage',\n",
    "        'purchase_count_estimated', 'user_id', 'user_idx', 'product_idx', 'scaled_rating'\n",
    "    ]\n",
    "    \n",
    "    # Kiểm tra và thêm các cột bổ sung nếu có\n",
    "    additional_columns = ['Search_Frequency', 'Timestamp', 'Generated_Keywords']\n",
    "    for col in additional_columns:\n",
    "        if col in df.columns:\n",
    "            final_columns.append(col)\n",
    "    \n",
    "    # Lọc các cột có trong DataFrame\n",
    "    existing_columns = [col for col in final_columns if col in df.columns]\n",
    "    df = df[existing_columns]\n",
    "\n",
    "    # Round numeric columns\n",
    "    columns_to_round = ['rating', 'rating_count', 'review_count', 'discounted_price', \n",
    "                        'actual_price', 'discount_percentage', 'purchase_count_estimated', 'scaled_rating']\n",
    "    for col in columns_to_round:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].round(1)\n",
    "\n",
    "    # Save cleaned data\n",
    "    try:\n",
    "        df.to_csv(\"amazon_cleaned.csv\", index=False)\n",
    "        print(\"\\nCleaned data saved to amazon_cleaned.csv\")\n",
    "        print(f\"Final shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "        print(\"\\nFinal columns:\")\n",
    "        for col in df.columns:\n",
    "            print(f\"  - {col}\")\n",
    "        \n",
    "        # Lưu class_weights để sử dụng sau này\n",
    "        import json\n",
    "        with open(\"class_weights.json\", \"w\") as f:\n",
    "            json.dump(class_weights, f)\n",
    "        print(\"Class weights saved to class_weights.json\")\n",
    "        \n",
    "        # Phân tích dữ liệu đã xử lý\n",
    "        plot_analysis(df)\n",
    "        return df, class_weights\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving file: {str(e)}\")\n",
    "        print(f\"Traceback: {traceback.format_exc()}\")\n",
    "        return None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_processed, class_weights = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0ef52a-cd6c-4ee5-a636-cf7094c14e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating\n",
      "4.5    51700\n",
      "4.4    48097\n",
      "4.3    44363\n",
      "4.6    43767\n",
      "4.2    41144\n",
      "4.0    38887\n",
      "5.0    38412\n",
      "4.1    37206\n",
      "4.7    31129\n",
      "3.9    29121\n",
      "3.8    26361\n",
      "3.7    23611\n",
      "3.6    20378\n",
      "2.7    19143\n",
      "3.5    18654\n",
      "4.8    15375\n",
      "3.4    15119\n",
      "3.3    13433\n",
      "3.0    12138\n",
      "3.2    10394\n",
      "3.1     8482\n",
      "4.9     4567\n",
      "2.9     4358\n",
      "2.8     3298\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Phân bố sau cân bằng:\n",
      "rating\n",
      "4.8    3298\n",
      "4.3    3298\n",
      "4.2    3298\n",
      "4.1    3298\n",
      "4.5    3298\n",
      "3.2    3298\n",
      "4.0    3298\n",
      "3.8    3298\n",
      "3.4    3298\n",
      "4.6    3298\n",
      "3.7    3298\n",
      "2.8    3298\n",
      "4.7    3298\n",
      "3.3    3298\n",
      "3.6    3298\n",
      "3.0    3298\n",
      "4.4    3298\n",
      "5.0    3298\n",
      "3.1    3298\n",
      "2.9    3298\n",
      "3.5    3298\n",
      "4.9    3298\n",
      "3.9    3298\n",
      "2.7    3298\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Đọc dữ liệu\n",
    "df = pd.read_csv(\"amazon_cleaned.csv\")\n",
    "\n",
    "# Kiểm tra phân bố rating hiện tại\n",
    "print(df['rating'].value_counts())\n",
    "\n",
    "# Xác định số lượng nhỏ nhất trong các rating để cân bằng\n",
    "min_count = df['rating'].value_counts().min()\n",
    "\n",
    "# Cân bằng từng lớp rating\n",
    "balanced_df = pd.concat([\n",
    "    resample(df[df['rating'] == r], replace=False, n_samples=min_count, random_state=42)\n",
    "    for r in sorted(df['rating'].unique())\n",
    "])\n",
    "\n",
    "# Shuffle lại dữ liệu\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Kiểm tra lại phân bố\n",
    "print(\"\\nPhân bố sau cân bằng:\")\n",
    "print(balanced_df['rating'].value_counts())\n",
    "\n",
    "# Lưu kết quả\n",
    "balanced_df.to_csv(\"amazon_rating_balanced.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
